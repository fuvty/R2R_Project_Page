<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Roads to Rome (R2R)">
  <meta name="keywords" content="A neural token routing method that selectively utilizes LLMs only for critical, path-divergent tokens, while leaving the majority of token generation to the SLM.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Roads to Rome (R2R): Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/token-visualization.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/token-visualization.js"></script>
  
  <!-- MathJax Configuration -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$']],
        displayMath: [['$$', '$$'], ['\[', '\]']],
        processEscapes: true
      },
      svg: {
        fontCache: 'global'
      },
      startup: {
        elements: ['.math-content'] // Only process elements with this class
      }
    };
  </script>
  <!-- MathJax for rendering LaTeX math expressions -->
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="columns is-centered is-vcentered">
            <div class="column is-2">
              <img src="./static/images/logo.png" alt="Logo" class="logo-image">
            </div>
            <div class="column has-text-left">
              <h1 class="title is-1 publication-title">Roads to Rome (R2R):<br> Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing</h1>
            </div>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/TianyuFu">Tianyu Fu</a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a>Yi Ge</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a>Yichen You</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/EnshuLiu">Enshu Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://zhihang.cc/">Zhihang Yuan</a><sup>2</sup>,</span><br>
            <span class="author-block">
              <a href="https://dai.sjtu.edu.cn/pepledetail.html?id=218">Guohao Dai</a><sup>2,3</sup>,</span>
            <span class="author-block">
              <a>Shengen Yan</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a>Huazhong Yang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://nicsefc.ee.tsinghua.edu.cn/people/YuWang">Yu Wang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>Infinigence AI,</span>
            <span class="author-block"><sup>3</sup>Shanghai Jiao Tong University</span>
            <br>
            <span class="author-block"><sup>*</sup><i>Equal contribution</i></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2501.01986"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- arXiv Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2501.01986"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/thu-nics/R2R"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
          
          <!-- Paper Release Notice -->
          <div class="column has-text-centered" style="margin-top: 1.5rem;">
            <div class="notification is-info is-light" style="display: inline-block; padding: 1rem 2rem; border-radius: 8px;">
              <span class="icon">
                <i class="fas fa-clock"></i>
              </span>
              <span><strong>Arxiv Paper Coming Soon!</strong> We are preparing to release our full paper. Stay tuned for updates.</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/key_notion.png" alt="R2R Overview" style="width: 100%; max-width: 1200px; margin: 0 auto; display: block;">
      <h2 class="subtitle has-text-centered">
        <span class="r2r">Roads to Rome (R2R)</span> selectively utilizes LLMs only for critical, path-divergent tokens, leaving the majority of token generation to the SLM.
        With an average activated parameter size of 5.6B, R2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the R1-14B model.
      </h2>
    </div>
  </div>
</section>

<!-- Token Visualization Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Path-Following Routing Illustration</h2>
        
        <!-- Math Problem Question -->
        <div class="content has-text-left math-content" style="background-color: #f5f5f5; padding: 1.5rem; border-radius: 6px; margin-bottom: 2rem;">
          <h3 class="title is-5">Example Problem:</h3>
          <p>
            Every morning Aya goes for a $9$-kilometer-long walk and stops at a coffee shop afterwards. When she walks at a constant speed of $s$ kilometers per hour, the walk takes her 4 hours, including $t$ minutes spent in the coffee shop. When she walks $s+2$ kilometers per hour, the walk takes her 2 hours and 24 minutes, including $t$ minutes spent in the coffee shop. Suppose Aya walks at $s+\frac{1}{2}$ kilometers per hour. Find the number of minutes the walk takes her, including the $t$ minutes spent in the coffee shop.
          </p>
        </div>
        
        <!-- Collapsible token visualization -->
        <div class="content has-text-left math-content" style="background-color: #f5f5f5; padding: 1.5rem; border-radius: 6px; margin-bottom: 2rem;">
          <div id="mix-inference-heading-container" style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
            <h3 class="title is-5" style="margin-bottom: 0;">Mix inference response:</h3>
            <div style="display: flex; gap: 0.5rem;">
              <button class="button is-small" id="play-btn" aria-label="play visualization">
                <span class="icon is-small"><i class="fas fa-play" aria-hidden="true"></i></span>
              </button>
              <button class="button is-small" id="restart-btn" style="display: none;" aria-label="restart visualization">
                <span class="icon is-small"><i class="fas fa-history" aria-hidden="true"></i></span>
              </button>
              <button class="button is-small" id="fast-forward-btn" style="display: none;" aria-label="fast forward">
                <span class="icon is-small"><i class="fas fa-fast-forward" aria-hidden="true"></i></span>
              </button>
            </div>
          </div>
          <div id="token-viz-container" style="display: none;">
            <div class="token-display-container">
              <div class="legend-instruction-wrapper">
                <div class="token-legend">
                  <div class="legend-item">
                    <div class="legend-color legend-color-small"></div>
                    <span>Identical (use SLM)</span>
                  </div>
                  <div class="legend-item">
                    <div class="legend-color legend-color-small-diff"></div>
                    <span>Neutral (use SLM)</span>
                  </div>
                  <div class="legend-item">
                    <div class="legend-color legend-color-large"></div>
                    <span>Divergent (use LLM)</span>
                  </div>
                </div>
                <p class="token-instruction" style="padding: 0.25rem 0; margin: 0;">Hover over blue or red text to see why R2R makes such routing choices.</p>
              </div>
              <div id="token-content" class="token-content"></div>
            </div>
          </div>
        </div>
        
        <!-- Add toggle script -->
        <script>
          document.addEventListener('DOMContentLoaded', function() {
            const playButton = document.getElementById('play-btn');
            const restartButton = document.getElementById('restart-btn');
            const fastForwardButton = document.getElementById('fast-forward-btn');
            const tokenVizContainer = document.getElementById('token-viz-container');
            const tokenContent = document.getElementById('token-content');
            const mixInferenceHeadingContainer = document.getElementById('mix-inference-heading-container');
            
            let animationRunning = false;
            let typeNextTokenTimeout;
            let allTokens = [];
            let currentTokenIndex = 0;

            function resetVisualization() {
              clearTimeout(typeNextTokenTimeout);
              animationRunning = false;
              currentTokenIndex = 0;
              if (allTokens.length > 0) {
                allTokens.forEach(token => token.style.display = 'none');
              }
              tokenVizContainer.style.display = 'none';
              mixInferenceHeadingContainer.style.marginBottom = '0.5rem';
              playButton.style.display = 'block';
              restartButton.style.display = 'none';
              fastForwardButton.style.display = 'none';
            }

            function startAnimation() {
              if (tokenContent && tokenContent.children.length > 0) {
                allTokens = Array.from(tokenContent.children);
                allTokens.forEach(token => token.style.display = 'none');
                currentTokenIndex = 0;
                animationRunning = true;
                tokenVizContainer.style.display = 'block'; 
                mixInferenceHeadingContainer.style.marginBottom = '1.5rem'; 
                typeNextToken();
              }
            }

            function typeNextToken() {
              if (!animationRunning) return;

              if (currentTokenIndex < allTokens.length) {
                const currentToken = allTokens[currentTokenIndex];
                currentToken.style.display = 'inline';
                
                let delay = 50;
                if (currentToken.classList.contains('token-type-0') || currentToken.classList.contains('token-type-1')) {
                  delay = 20;
                } else if (currentToken.classList.contains('token-type-2')) {
                  delay = 250;
                }
                
                currentTokenIndex++;
                typeNextTokenTimeout = setTimeout(typeNextToken, delay);
              } else {
                // Animation finished naturally
                animationRunning = false; // Crucial: mark animation as not running
                fastForwardButton.style.display = 'none'; // Hide FF
                // restartButton remains visible, playButton remains hidden
              }
            }

            playButton.addEventListener('click', function() {
              playButton.style.display = 'none';
              restartButton.style.display = 'block';
              fastForwardButton.style.display = 'block';
              startAnimation();
            });

            restartButton.addEventListener('click', function() {
              if (animationRunning) {
                // Clicked during animation: reset completely
                resetVisualization();
              } else {
                // Clicked after animation finished (or after FF): Replay
                playButton.style.display = 'none'; // Ensure play is hidden
                restartButton.style.display = 'block'; // Keep restart visible
                fastForwardButton.style.display = 'block'; // Show FF again for the replay
                startAnimation(); // This will reset tokens and start typing
              }
            });

            fastForwardButton.addEventListener('click', function() {
              if (animationRunning) {
                clearTimeout(typeNextTokenTimeout);
                animationRunning = false; // Mark animation as not running
                allTokens.forEach((token, index) => {
                  if (index >= currentTokenIndex) token.style.display = 'inline';
                });
                tokenContent.style.display = 'block';
                
                fastForwardButton.style.display = 'none'; // Hide FF
                // restartButton remains visible, playButton remains hidden
              }
            });
          });
        </script>
        
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) achieve impressive reasoning capabilities at the cost of substantial inference overhead, posing substantial deployment challenges.
            Although distilled Small Language Models (SLMs) significantly enhance efficiency, their performance suffers as they fail to follow LLMs' reasoning paths.
            Luckily, we reveal that only a small fraction of tokens genuinely diverge reasoning paths between LLMs and SLMs. Most generated tokens are either identical or exhibit neutral differences, such as minor variations in abbreviations or expressions.
          </p>
          <p>
            Leveraging this insight, we introduce <strong>Roads to Rome (R2R)</strong>, a neural token router that selectively utilizes LLMs only for these critical, path-divergent tokens, while leaving the majority of token generation to the SLM.
            We also develop an automatic data generation pipeline that identifies divergent tokens and generates token-level routing labels to train the lightweight router.
          </p>
          <p>
            We apply R2R to combine R1-1.5B and R1-32B models from the DeepSeek family, and evaluate on challenging math, coding, and QA benchmarks.
            With an average activated parameter size of 5.6B, R2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the R1-14B model.
            Compared to R1-32B, it delivers a 2.8x wall-clock speedup with comparable performance, advancing the Pareto frontier of test-time scaling efficiency.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method Overview -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method Overview</h2>

        <div class="content">
          <h3 class="title is-5">Core idea of R2R</h3>
          <p>
            The core idea of Roads to Rome (R2R) is to selectively use a large language model (LLM) only for critical, path-divergent tokens, while relying on a more efficient small language model (SLM) for the majority of token generation. Essentially, R2R tries to <strong>let the SLM follows LLM reasoning path by correcting only the divergent tokens</strong>.
          </p>

          <h4 class="title is-5">Path-Following Routing Strategy</h4>
          <p>
            To achieve this, R2R employs a path-following routing strategy. At each step, it compares SLM and LLM next-token predictions. If identical, the SLM token is used. If different, a continuation-and-verification mechanism determines if the difference is 'neutral' (not affecting the reasoning outcome) or 'divergent' (altering the reasoning path). Divergent tokens are routed to the LLM for correction, ensuring the generation stays aligned with the LLM's intended path. This is formalized by checking if an LLM-based continuation from the SLM's differing token maintains quality compared to an LLM-based continuation from the LLM's token.
          </p>
          
          <!-- Routing strategy figure -->
          <div class="columns is-centered">
            <div class="column is-10">
              <img src="./static/images/data_gen_overview.png" alt="R2R Labeling Method" class="method-figure">
              <p class="caption">
                R2R's data labeling pipeline: LLM generates a response. SLM prefills to find different tokens. LLM continues from these points. A verifier labels differences as neutral or divergent.
              </p>
            </div>
          </div>
  
          <h4 class="title is-5">Router Training and Routing Scheme</h4>
          <p>
            The path-following routing strategy generates a large amount of model preference labels for training the router. The router, a small feed-forward network, learns to predict divergence based on SLM logits, token embeddings, and last-layer hidden states, enabling immediate routing decisions during inference.
          </p>
          
          <!-- Routing scheme figure -->
          <div class="columns is-centered">
            <div class="column is-6">
              <img src="./static/images/main_method.png" alt="R2R Routing Method" class="method-figure">
              <p class="caption">
                R2R uses neural router to inspect SLM outputs at each step, immediately corrects divergent tokens with LLM, then continues generation from the corrected outputs.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Method Overview -->
    <h2 class="title is-3">Key Observations & Design</h2>
    
    <div class="columns equal-height-columns">
      <!-- Observation 1 -->
      <div class="column">
        <div class="content observation-content">
          <h3 class="title is-5">Observation 1:<br>Token Divergence Rarity</h3>
          <div class="observation-image-container">
            <img src="./static/images/distribution.png" alt="Distribution of identical, neutral, and divergent tokens">
          </div>
          <div class="observation-text">
            <p>Only a small fraction of tokens genuinely diverge reasoning paths between LLMs and SLMs. Most are identical or neutral.</p>
          </div>
          <div class="observation-arrow">
            <span class="icon has-text-info">
              <i class="fas fa-arrow-down"></i>
            </span>
          </div>
          <div class="observation-design">
            <p><strong>Design Choice:</strong> Selectively use LLMs only for critical, path-divergent tokens. SLM handles the majority.</p>
          </div>
        </div>
      </div>

      <!-- Observation 2 -->
      <div class="column">
        <div class="content observation-content">
          <h3 class="title is-5">Observation 2:<br>SLM Entropy as Indicator</h3>
          <div class="observation-image-container">
            <img src="./static/images/entropy_distribution.png" alt="SLM entropy distribution for divergent vs. non-divergent tokens">
          </div>
          <div class="observation-text">
            <p>Divergent tokens exhibit substantially higher entropy in the SLM's output logits.</p>
          </div>
          <div class="observation-arrow">
            <span class="icon has-text-info">
              <i class="fas fa-arrow-down"></i>
            </span>
          </div>
          <div class="observation-design">
            <p><strong>Design Choice:</strong> Router utilizes top SLM logit values as an input feature to predict divergence.</p>
          </div>
        </div>
      </div>

      <!-- Observation 3 -->
      <div class="column">
        <div class="content observation-content">
          <h3 class="title is-5">Observation 3:<br>Token Frequency Matters</h3>
          <div class="observation-image-container">
            <img src="./static/images/token_divergence_frequency.png" alt="Divergence rate vs. token frequency">
          </div>
          <div class="observation-text">
            <p>Low-frequency tokens are more likely to be divergent due to limited SLM capacity for rare tokens.</p>
          </div>
          <div class="observation-arrow">
            <span class="icon has-text-info">
              <i class="fas fa-arrow-down"></i>
            </span>
          </div>
          <div class="observation-design">
            <p><strong>Design Choice:</strong> Router incorporates token embeddings as input, capturing token-frequency biases.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Experiment Results</h2>

    <!-- Performance vs Efficiency Table -->
    <div class="content">
      <h3 class="title is-5">Performance and Efficiency Comparisons</h3>
      <table class="table is-fullwidth is-hoverable">
        <thead>
          <tr>
            <th>Method</th>
            <th>Accuracy</th>
            <th>Avg. Param.</th>
            <th>Cost (K*B)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>R1-1.5B (SLM)</td>
            <td>10%</td>
            <td>1.5B</td>
            <td>42</td>
          </tr>
          <tr>
            <td>R1-7B</td>
            <td>28%</td>
            <td>7.0B</td>
            <td>154</td>
          </tr>
          <tr>
            <td>R1-14B</td>
            <td>43%</td>
            <td>14.0B</td>
            <td>234</td>
          </tr>
          <tr>
            <td>R1-32B (LLM)</td>
            <td>50%</td>
            <td>32.0B</td>
            <td>537</td>
          </tr>
          <tr>
            <td><strong>R2R (Ours)</strong></td>
            <td><strong>46%</strong></td>
            <td><strong>5.6B</strong></td>
            <td><strong>103</strong></td>
          </tr>
        </tbody>
      </table>
      <p class="has-text-left math-content">
        By combining the R1-1.5B SLM and the R1-32B LLM, R2R achieves impressive efficiency with only <strong>5.6B</strong> average activated parameters.
      </p>
      <ul class="math-content">
        <li>Compared to the SLM baseline, R2R delivers <strong>4.6$\times$</strong> higher accuracy than R1-1.5B.</li>
        <li>When compared to mid-sized models, R2R achieves <strong>1.5$\times$</strong> speedup with <strong>1.1$\times$</strong> accuracy over R1-14B.</li>
        <li>Against the full R1-32B LLM, it delivers a <strong>2.8$\times$</strong> end-to-end inference speedup while still reaching 92% of the LLM's accuracy—all while using the LLM for only 11%–15% of generated tokens.</li>
      </ul>
    </div>

    <!-- Scaling Behavior and Speedup -->
    <div class="content">
      <h3 class="title is-5">Scaling Behavior</h3>
      <div class="columns is-centered">
        <div class="column is-10">
          <img src="./static/images/all_pareto_subplots_params.png" alt="Accuracy vs. Average Activated Parameters per Token">
          <p class="caption has-text-centered">
            R2R advances the Pareto frontier for accuracy versus average activated parameters, outperforming distillation and query-level routing methods.
          </p>
        </div>
      </div>
      <p class="has-text-left math-content">
        These results demonstrate that R2R effectively balances performance and efficiency, offering substantial computational savings while maintaining high-quality outputs across challenging benchmarks.
      </p>
    </div>

    <!-- Visualizing Routing Behavior -->
    <div class="content">
      <h3 class="title is-5">Visualizing R2R Routing Behavior</h3>
      <div class="columns is-centered">
        <div class="column is-8">
          <img src="./static/images/routing_observation.png" alt="LLM usage rate at different positions">
          <p class="caption has-text-centered">
           (a) LLM usage across the entire thinking and reply process. (b) LLM usage within each thought segment. R2R routes fewer tokens to LLM during replies and relies more on LLM at the beginning/end of thoughts.
          </p>
        </div>
      </div>
      <p class="has-text-left math-content">
        Analysis of R2R routing behavior on the AIME benchmark reveals several key insights:
      </p>
      <ul class="math-content">
        <li>R2R routes fewer tokens to the LLM during the reply phase compared to the thinking process. It reflects that after deep reasoning, generating the final answer is relatively straightforward.</li>
        <li>Within individual thought segments, R2R relies more heavily on the LLM at the beginning and end of each thought, where tokens determine reasoning direction and whether to continue, branch, or conclude.</li>
        <li>These efficient routing patterns <strong>emerge naturally</strong> from the router training process without explicit rules, highlighting R2R's ability to learn efficient resource allocation.</li>
      </ul>
    </div>
  </div>
</section>


<!-- Live Demo Section -->
<section class="section" id="LiveDemo">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Mix Inference Demo</h2>
        <p class="subtitle">See R2R (right) run in action, along with R1-32B (left)</p>
        
        <div class="content">
          <div style="text-align: center;">
            <video src="./static/videos/R2R_demo.mp4" alt="R2R Live Demo" class="demo-gif" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" loop muted playsinline controls loading="lazy"></video>
          </div>
          <p class="caption">
            R2R in action: red tokens are routed to the LLM, while blue tokens are generated by the SLM, demonstrating efficient token-level routing.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>
      We welcome you to explore our repository and cite our paper if you find the results interesting or useful for your research.
    </p>
    <pre><code>@article{fu2025r2r,
  title     = {Roads to Rome (R2R): Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing},
  author    = {Tianyu Fu and Yi Ge and Yichen You and Enshu Liu and Zhihang Yuan and Guohao Dai and Shengen Yan and Huazhong Yang and Yu Wang},
  year      = {2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/pdf/2501.01986">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="YOUR_CODE_LINK_HERE" class="external-link">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template borrowed from <a href="https://nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
